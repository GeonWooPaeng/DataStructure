- Bubble Sort(옆에 있는 애랑 비교)

1. for num in range(len(data_list)) 반복
2. swap = False (교환이 되었는지를 확인하는 변수를 두자)
3. 반복문 안에서, for index in range(len(data_list) - num - 1) n-1번 반복해야 하므로
4. 반복문안의 반복문 안에서, if data_list[index] > data_list[index + 1] 이면
5. data_list[index], data_list[index + 1] = data_list[index + 1], data_list[index]
6. swap = True 
7. 반복문 안에서, if swap == False 이면, break 끝


- Selection Sort(기준점이랑 기준점 밑중 최솟값을  비교, 기준점 +=1 )

1. for stand in range(len(data_list) - 1)로 반복
2. lowest = stand 로 놓고,
3. for num in range(stand, len(data_list)) stand 이후부터 반복
	- 내부 반복문 안에서 data_list[lowest] > data_list[num]이면, 
		- lowest = num
4. data_list[stand], data_list[lowest] = data_list[lowest], data_list[stand] 


- Insertion sort(값을 빼놓고 순서가 앞인 애들과 비교)

1.
def insertion_sort(data):
    for index in range(len(data)-1):
        for index2 in range(index +1, 0, -1):
            if data[index2] < data[index2 -1]:
                data[index2], data[index2 - 1] = data[index2 - 1], data[index2]
            else:
                break
    return data


- Recursive call(재귀용법 - 함수안에 동일한 함수 호출)

1.
def fuction(입력):
    if 입력 > 일정값: 
        return function(입력보다 작은 값)
    else:
        return 일정값, 입력값, 또는 특정값
2.
def function(입력):
    if 입력 <= 일정값:
        return 일정값, 입력값, 또는 특정값 
    fuction(입력보다 작은 값) 
    return 결과값


- Dynamic Programming(동적 계획법)과 Divide and Conquer(분할 정복)

1. 공통점
	- 문제를 잘게 쪼개서, 가장 작은 단위로 분할
2. 차이점
	-동적 계획법
		- 부분 문제는 중복되어, 상위 문제 해결 시 재활용 됨
		- Memoization 기법 사용 (부분 문제의 해답을 저장해서 재활용하는 최적화 기법으로 사용)

	- 분할 정복
		- 부분 문제는 서로 중복되지 않음 
		- Memorization 기법 사용 안함


- Quick Sort(퀵 정렬 - pivot(기준점)을 정하여 크기에 따라 왼쪽과 오른쪽으로 나누는 함수를 반복하여 리턴하는 것)

1. 만약 리스트 갯수가 한개이면 해당 리스트 리턴
2. 그렇지 않으면, 리스트 맨 앞의 데이터를 기준점(pivot)으로 놓기
3. left, right 리스트 변수를 만들고,
4. 맨 앞의 데이터를 뺀 나머지 데이터를 기준점과 비교(pivot)
	- 기준점보다 작으면 left.append(해당 데이터)
	- 기준점보다 크면 right.append(해당 데이터)
5. return quicksort(left) + pivot + quicksort(right) 로 재귀 호출( 리스트로 만들어서 리턴)

1.
def qsort(data):
    if len(data) <= 1:
        return data 
    
    left, right = list(), list() 
    pivot = data[0]

    for index in range(1, len(data)):
        if pivot > data[index]:
            left.append(data[index])
        else:
            right.append(data[index])

    return qsort(left) + [pivot] + qsort(right)

2.
def qsort(data):
    if len(data) <= 1:
        return data 
   
    pivot = data[0] 

    left = [ item for item in data[1:] if pivot > item]
    right = [ itme for item in data[1:] if pivot <= item]

    return qsort(left) + [pivot] + qsort(right)


- Merge Sort(병합 정렬 - 다 분리해서 합병해 나간다 )

1.
def split(list):
    if len(list) <= 1:
        return list 
    데이터 2등분 = list//2
    left = list[: 데이터 2등분]
    right = list[데이터 2등분 :]
        return merge(split(left),split(right))

def merge(left, right):
    list = list()
    lp,rp = 0,0
    if left[lp] < right[rp]:
        list.append(left[lp])
        lp += 1
    else:
        list.append(right[rp])
        rp += 1
    return list


- Sequential Search(순차 탐색 - 리스트를 앞에서 부터 하나씩 비교해서 원하는 데이터 찾는 방법)

1.
def sequencial(data_list, search_data):
    for index in range(len(data_list)):
        if data_list[index] == search_data:
            return index
    return -1


- Binary Search(이진 탐색 - 탐색할 자료를 둘로 나눠 해당 데이터가 있을 만한 곳 탐색)

1. 이진 탐색은 데이터가 정렬되있는 상태에서 진행
2. 데이터가 [2, 3, 8, 12, 20] 일 때,
	- binaray_search(data_list, find_data) 함수를 만들고
		- find_data는 찾는 숫자
		- data_list는 데이터 리스트
		- data_list의 중간값을 find_data와 비교해서
			- find_data < data_list의 중간값 이라면
				- 맨 앞부터 data_list의 중간까지에서 다시 find_data 찾기
			- data_list의 중간값 < find_data 이라면
				- data_list의 중간부터 맨 끝까지에서 다시 find_data 찾기
			- 그렇지 않다면, data_list의 중간값은 find_data인 경우로, return data_list 중간 위치 

1.
def binary_search(data, search):
    data.sort()
    print(data)
    if len(data) == 1 and search == data[0]:
        return True
    if len(data) == 1 and search != data[0]:
        return False
    if len(data) == 0:
        return False 

    medium = len(data) // 2
    if search == data[medium]:
        return True 
    else:
        if search > data[medium]:
            return binary_search(data[medium+1:], search)
        else:
            return binary_search(data[:medium], search)

- Graph(그래프)
    - 실제 세계의 현상이나 사물을 정점(Vertex) 또는 노드(Node) 와 간선(Edge, Link, Branch)로 표현하기 위해 사용


- BFS(너비 우선 탐색)

1. 우선 첫번째 key를 need_visit 큐에 넣는다.
2. need_visit의 0번째 가 빠질때 0번째가 visited 큐에 없으면 
3. visited 큐에 0번째를 채워 넣고 need_visit 큐에 해당 value를 넣는다.
4. 계속 반복 하여 need_visit 큐에 아무 것도 없을 시 정지 한다.
 
graph = dict() 
graph['A'] = ['B', 'C']
graph['B'] = ['A', 'D']
graph['C'] = ['A', 'G', 'H', 'I']
graph['D'] = ['B', 'E', 'F']
graph['E'] = ['D']
graph['F'] = ['D']
graph['G'] = ['C']
graph['H'] = ['C']
graph['I'] = ['C', 'J']
graph['J'] = ['I']

def bfs(graph, start_node):
    visited = list()  # queue
    need_visit = list()  #queue
    
    need_visit.append(start_node)
    count = 0

    while need_visit:
        count += 1
        node = need_visit.pop(0)
        if node not in visited:
            visited.append(node)
            need_visit.extend(graph[node])
    print(count)

    return visited

- DFS(깊이 우선 탐색)

1. 우선 첫번째 값을 need_visit 스택에 넣는다.
2. need_visit 맨 마지막 값을 꺼낸 후 그 값이 visited큐 에 없을 시 visited 큐에 넣는다.
3. 그리고 꺼낸 값의 value를 need_visit 스택에 추가 한다.
4. need_visit가 없어질 때 까지 반복한다.

def dfs(graph, start_node):
    visited = list()  #queue
    need_visit = list()  #stack 

    need_visit.append(start_node)

    while need_visit: 
        node = need_visit.pop()
        if node not in visited:
            visited.append(node)
            need_visit.extend(graph[node])

    return visited


- Union-Find(합 집합 찾기 - 부모 테이블을 이용해서 자신이 어떤 곳에 속해있는지 알기)
	- 원소들의 연결 여부를 확인하는 알고리즘

def find(x):
    if x == parent[x]:
        return x
    else:
        p = find(parent[x])
        parent[x] = p 
        return parent[x]

def union(x, y):
    x = find(x)
    y = find(y)

    parent[y] = x


- Counting Sort(계수 정렬 - 수의 범위가 정해져 있을 때의 알고리즘)
	- 원소간 비교하지 않고 각 원소가 몇 개 등장하는지 갯수를 세서 정렬하는 알고리즘
	- 그리고 각 원소의 갯수만큼 출력된다.
	- 배열의 크기는 데이터의 범위를 포함 해야한다.
	- EX) 파이썬에서 데이터 개수 많을 때 input() 대신 sys.stdin.readline() 을 사용한다.

import sys
n = int(sys.stdin.readline())
array = [0] * 10001

#각 원소 수 += 1
for i in range(n):
    data = int(sys.stdin.readline())
    array[data] += 1

#계수 정렬 출력 코드
for i in range(10001):
    if array[i] != 0:
        for j in range(array[i]):
            print(i)


<순회> 
    > 트리 모든 node를 돌아야 한다 
    > 노드가 비어 있어도 있다고 가정하고 푼 후 나중에 지우자!!!

class Node:
    def __init__(self, data, left_node, right_node):
        self.data = data 
        self.left_node = left_node 
        self.right_node = right_node 

- Preorder Traversal(전위 순회)
	루트(Root부터 자식 끝까지 탐색후 시작) -> 왼쪽 자식 -> 오른쪽 자식
     	    > Root 먼저 방문, DFS랑 좀 닮음, 
	    > 노드와 처음 마주칠때 방문

def pre_order(tree):
    if tree == None:
        return 
    
    print(tree.data)

    pre_order(tree.left_node)
    pre_order(tree.right_node)

- Inorder Traversal(중위 순회)
	왼쪽 자식(맨 하단부터) -> 루트 -> 오른쪽 자식
	    > 왼쪽 하위 트리를 방문한 후 Root를 방문, 
	    > 왼쪽으로 갔다가(왼쪽 끝까지 갔다가) 다시 올라올 때 방문

def in_order(tree):
    if tree == None:
        return 

    in_order(tree.left_node)

    print(tree.data)

    in_order(tree.right_node)

-Postorder Traversal(후위 순회)
	왼쪽 자식(맨 하단부터) -> 오른쪽 자식 -> 루트
	    > 하위 트리 모두 방문 후 Root를 방문
	    > 오른쪽으로 갔다가(오른쪽 끝까지 간 후) 다시 올라올 때 방문

​def post_order(node):
    if tree == None:
        return 
    
    post_order(tree.left_node)
    post_order(tree.right_node)

    print(tree.data)

- 다익스트라(dijkstra)

import heapq

def dijkstra(graph, start, end):
    distances = {vertex: [float('inf'), start] for vertex in graph}
    distances[start] = [0,start]
    queue = []

    heapq.heappush(queue,[distances[start][0], start])

    while queue:

        current_distance, current_vertex = heapq.heappop(queue)

        if distances[current_vertex][0] < current_distance:
            continue
        
        for adjacent, weight in graph[current_vertex].items():
            distance = current_distance + weight 
            if distance < distances[adjacent][0]:
                distances[adjacent] = [distance,current_vertex]
                heapq.heappush(queue,[distance,adjacent])
    
    path = end 
    path_output = end + '->' 
    while distances[path][1] != start:
        path_output += distances[path][1] + '->'
        path = distances[path][1]
    path_output += start 
    print(path_output)
    return distnaces

- kruskal알고리즘
parent = dict()  # 각각 node의 부모 node 저장
rank = dict()   # 각각 node의 rank 값 

def make_set(node): # 각각 원소 node의 초기화
    parent[node] = node # node가 1개 (root가 자기자신)
    rank[node] = 0

    
def find(node): # 각 node의 root 노드 찾기
    # path compression
    if parent[node] != node: 
        parent[node] = find(parent[node])
    return parent[node]


def union(node_v,node_u): # 노드 연결
    # union by rank 
    #각각 root node 알기
    root1 = find(node_v)
    root2 = find(node_u)
    
    # rank 알아내기 (이해하기!!)
    if rank[root1] > rank[root2]:
        parent[root2] = root1
    else:
        parent[root1] = root2 
        
        if rank[root1] == rank[root2]:
            rank[root2] += 1  #rank 올려주기 (아무거나 올려도 상관 없다.)
            
            
    
def kruskal(graph):
    mst = list() # cycle이 없으면 간선을 넣어 주는 곳 , 이곳에 들어 온 합은 최소 신장트리
    
    #1. 초기화
    for node in graph['vertices']:
        make_set(node)
    
    #2. 간선 weight 기반 sorting
    edges = graph['edges']
    edges.sort()
    
    #3. 간선 연결(사이클 없는)
    for edge in edges: #간선 꺼내기
        weight, node_v, node_u = edge
        # cycle 파악 후 합치기
        if find(node_v) != find(node_u): # 같지 않으면 cycle 없다는 것!!
            union(node_v,node_u)  # node 합치기 
            mst.append(edge)
            
    return mst 

- prim 알고리즘 - 간선중심
from collections import defaultdict
from heapq import*

def prim(start_node,edges):
    mst = list() #최소신장트리 간선 list
    
    adjacent_edges = defaultdict(list) #dictlist만들어 준다. key -> 각각node, value -> 간선 정보 list 
    #특정 node의 정보 각각 정리
    for weight,n1,n2 in edges:
        adjacent_edges[n1].append((weight,n1,n2))
        adjacent_edges[n2].append((weight,n2,n1))

    connected_nodes = set(start_node) #연결된 node 집합
    
    candidate_edge_list = adjacent_edges[start_node] #연결된 간선 list
    
    heapify(candidate_edge_list) #연결된 간선list heap구조로 바꿈 
    
    while candidate_edge_list: # 더이상 간선 list에 간선 없을 떄 까지 반복 
        weight,n1,n2 = heappop(candidate_edge_list) # 간선 list에서 간선 weight가 가장 작은 값 추출
        
        #인접 node가 연결된 node 잡합에 있는지 확인
        if n2 not in connected_nodes: #Cycle이 없으면
            connected_nodes.add(n2) #연결된 node집합에 넣는다.
            mst.append((weight,n1,n2))
            
            # 인접 node의 간선 정보를 간선list에 넣는곳
            for edge in adjacent_edges[n2]: #인접 node의 정보 가져오기
                if edge[2] not in connected_nodes: #인전 node가 연결된 node에 없을 시
                    heappush(candidate_edge_list,edge) #연결된 간선list에 간선 정보 넣는다.
    
    return mst

- prim 알고리즘 - node값 중심
from heapdict import heapdict #안에 있는 최소 데이터가 root가 되게 한다.

def prim(graph,start):
    mst = list()  #최소 간선 list 저장하는 곳
    keys = heapdict() # node별 key값을 가진 (heap 구조)
    pi = dict() # node가 변했을 때 영향을 받은 간선을 저장하는 곳
    total_weigth = 0  # 전체 간선의 total을 저장하는 곳
    
    for node in graph.keys():
        keys[node] = float('inf') # 무한대로 만듬 
        pi[node] = None  
    
    # 현재 선택한 node
    keys[start] = 0  
    pi[start] = start 
    
    
    while keys:
        current_node, current_key = keys.popitem()
        mst.append([pi[current_node], current_node,current_key]) # 선택된 최소 간선 mst에 넣기
        total_weight += current_key
        
        for adjacent, weight in mygraph[current_node].items():
            if adjacent in keys and weight < keys[adjacent]: #인접된 node가 선택되었는지 확인, 값 비교하기 
                keys[adjacent] = weight 
                pi[adjacent] = current_node
    
    return mst, total_weight